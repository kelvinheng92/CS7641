{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, average_precision_score, f1_score, silhouette_score, v_measure_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_from_clf(clf, X, Y, score_fn):\n",
    "    pred = clf.predict_proba(X)[:,1]\n",
    "    return score_fn(Y, pred)\n",
    "\n",
    "def custom_scorer(y_true, y_pred, actual_scorer):\n",
    "    score = np.nan\n",
    "\n",
    "    try:\n",
    "      score = actual_scorer(y_true, y_pred)\n",
    "    except Exception: \n",
    "      pass\n",
    "\n",
    "    return score\n",
    "\n",
    "seed = 0\n",
    "metric = 'aucprc'\n",
    "score_fn = average_precision_score\n",
    "auc_score = make_scorer(custom_scorer, actual_scorer = score_fn, needs_threshold=True)\n",
    "scoring = {metric: auc_score}\n",
    "full_df = pd.read_csv(\"dataset1/processed_full_data.csv\")\n",
    "trainval_df = pd.read_csv(\"dataset1/processed_trainval_data.csv\")\n",
    "test_df = pd.read_csv(\"dataset1/processed_test_data.csv\")\n",
    "\n",
    "dim_dict = {'pca': 10,\n",
    "            'ica': 10,\n",
    "            'rp': 10,\n",
    "            'isomap': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pca(X, dim_dict, seed):\n",
    "    print('######  Performing PCA  #######')\n",
    "    pca = PCA(n_components=dim_dict['pca'], random_state = seed)\n",
    "    trans_X = pca.fit_transform(X)    \n",
    "    return pca, trans_X\n",
    "\n",
    "def fit_ica(X, dim_dict, seed):\n",
    "    print('#########  Performing ICA  #########')\n",
    "    ica = FastICA(n_components=dim_dict['ica'], random_state = seed)\n",
    "    trans_X = ica.fit_transform(X)    \n",
    "    return ica, trans_X\n",
    "\n",
    "def fit_rp(X, dim_dict, seed):\n",
    "    print('#########  Performing RP  #########')\n",
    "    rp = GaussianRandomProjection(n_components=dim_dict['rp'], random_state = seed)\n",
    "    trans_X = rp.fit_transform(X)    \n",
    "    return rp, trans_X\n",
    "\n",
    "def fit_isomap(X, dim_dict, seed):\n",
    "    print('#########  Performing Isomap  #########')\n",
    "    isomap = Isomap(n_components=dim_dict['isomap'])\n",
    "    trans_X = isomap.fit_transform(X)    \n",
    "    return isomap, trans_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######  Performing PCA  #######\n",
      "(1552, 10)\n",
      "#########  Performing ICA  #########\n",
      "(1552, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/decomposition/_fastica.py:119: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "best_params = {'early_stopping': False, 'hidden_layer_sizes': (20, 8),\n",
    "               'learning_rate_init': 0.01, 'max_iter': 2146,\n",
    "               'validation_fraction': 0.248039966366824}\n",
    "algos_str = ['PCA', 'ICA', 'Random Projection', 'Isomap']\n",
    "\n",
    "features = list(set(full_df.columns) - set(['label']))\n",
    "full_X = full_df[features]\n",
    "full_Y = full_df['label']\n",
    "train_score = []\n",
    "val_score = []\n",
    "test_score = []\n",
    "time_list = []\n",
    "for dim_reduction_fn in [fit_pca, fit_ica, fit_rp, fit_isomap]:\n",
    "\n",
    "    trainval_X = trainval_df[features]\n",
    "    trainval_Y = trainval_df['label']\n",
    "    algo, trainval_trans_X = dim_reduction_fn(trainval_X, dim_dict, seed)\n",
    "    \n",
    "    test_X = test_df[features]\n",
    "    test_Y = test_df['label']\n",
    "    test_trans_X = algo.transform(test_X)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    trainval_trans_X = scaler.fit_transform(trainval_trans_X)\n",
    "    print(trainval_trans_X.shape)\n",
    "    test_trans_X = scaler.transform(test_trans_X)\n",
    "    \n",
    "    clf = MLPClassifier(random_state=seed, **best_params)\n",
    "    scores = cross_validate(clf, trainval_trans_X, trainval_Y, scoring=scoring, cv=3, return_train_score=True, return_estimator=True)\n",
    "\n",
    "    train_score.append(np.mean(scores[f'train_{metric}']))\n",
    "    val_score.append(np.mean(scores[f'test_{metric}']))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(random_state=seed, **best_params)\n",
    "    clf.fit(trainval_trans_X, trainval_Y)\n",
    "    time_taken = round(time.time() - start_time, 4)\n",
    "    \n",
    "    time_list.append(time_taken)\n",
    "    test_auc = get_auc_from_clf(clf, test_trans_X, test_Y, score_fn)\n",
    "    test_score.append(test_auc)\n",
    "        \n",
    "plt.figure()\n",
    "plt.title(\"AUCs vs algorithms\")\n",
    "plt.plot(algos_str, train_score, label = 'train_auc')\n",
    "plt.plot(algos_str, val_score, label = 'val_auc')\n",
    "plt.plot(algos_str, test_score, label = 'test_auc')\n",
    "plt.axhline(y=0.8390064818265703, color='r', linestyle='-', label = 'A1 valid auc')\n",
    "plt.axhline(y=0.5599280351451511, color='b', linestyle='-', label = 'A1 test auc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Time taken vs algorithms')\n",
    "plt.plot(algos_str, time_list, label = 'fit time')\n",
    "plt.axhline(y=0.2031, color='r', linestyle='-', label = 'A1 NN fit time')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
